{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aj1X6hXIeBBY"
      },
      "source": [
        "# **Task \\#4 A**: Machine Learning MC886/MO444\n",
        "##**Convolution Models and Transfer Learning**##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYWwk0S4eLdR",
        "outputId": "ab772f16-25f5-4d93-8e61-e853959c7cfb"
      },
      "outputs": [],
      "source": [
        "print('Gabriel Borges Gutierrez' + ' 237300')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NsCdWGgGeUFh"
      },
      "source": [
        "## Objective:\n",
        "\n",
        "The objective of this project is to implement alternative approaches to **Convolutional Neural Networks** (CNNs) and **Transfer Learning Techniques** in order to devise the most effective model for addressing the given problems.\n",
        "\n",
        "**Obs: In this work, you can use scikit-learn and PyTorch.**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IGqdjp8sehTI"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The COCO (Common Objects in Context) dataset is a widely used benchmark dataset in computer vision research. It serves as a valuable resource for various tasks including object recognition, segmentation, and captioning. The dataset comprises a vast collection of images, each meticulously annotated with detailed information about the objects present in the image. It covers a diverse range of object categories, encompassing everyday objects such as people, animals, vehicles, and household items.\n",
        "\n",
        "Dataset Information:\n",
        "\n",
        "- The dataset consists of approximately 115,000 images. However, for your convenience, you can work with a subset that contains at least 30,000 images. You can utilize the function get_partial_dataset to create this partial dataset.\n",
        "\n",
        "- The following code cell will download the dataset, but please note that if the runtime gets disconnected, you will need to download it again. In case the authorization key doesn't work, you can download the dataset from the links provided below.\n",
        "\n",
        "- The data is available at: ([Link of the Dataset](https://drive.google.com/drive/folders/12dZ4lkKkAZ6CKcvDtwzXSLrYOy_avWW8?usp=sharing)): ```Multiclass Classfication``` and ```COCO JSON```\n",
        "\n",
        "\n",
        "More information about the dataset: *Lin, Tsung-Yi, et al. \"Microsoft coco: Common objects in context.\" Computer Visionâ€“ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13. Springer International Publishing, 2014.*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a4e1ZRx4cLMX"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8UOfH175LyZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import glob as glob\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torch.optim as optim\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import models\n",
        "from tqdm.notebook import tqdm\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.transforms import Resize, Compose, ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from torch_snippets import *\n",
        "\n",
        "# suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-5Dc0kbs5V-H"
      },
      "source": [
        "## Classification Task with COCO"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KU32LXskohKJ"
      },
      "source": [
        "In the COCO dataset, each sample can have multiple labels. Therefore, using the CrossEntropy loss function, which relies on softmax activation, is not suitable for the multi-label classification problem. Let's explore why CrossEntropy is not appropriate in this case.\n",
        "\n",
        "![loss_definition_1](https://drive.google.com/uc?export=view&id=1BDkR2n6aNq6VvXnQNYw7dxtzfveijysB)\n",
        "\n",
        "The above image illustrates how we calculate the CrossEntropy loss in a simple multi-class classification scenario, where the target labels are mutually exclusive. The loss computation focuses on the logit corresponding to the true target label and its relative magnitude compared to other labels. However, softmax ensures that all predicted probabilities sum to 1, making it impossible to have several correct answers.\n",
        "\n",
        "![loss_definition_2](https://drive.google.com/uc?export=view&id=1tMQ0WFY1HAIlBnp3bSVic4gy1GJuJyc4)\n",
        "\n",
        "To address this, we need to treat each prediction independently. One solution is to use the Sigmoid function as a normalizer for each logit value individually. This way, we can have multiple correct labels and their respective predicted probabilities for each label. We can then compare these probabilities with the probabilities of the correct labels (set to 1) using the BinaryCrossEntropy loss.\n",
        "\n",
        "![loss_definition_3](https://drive.google.com/uc?export=view&id=1Mp5lo3EFEM7vMNE_5TM-Zts1NgY8oTrn)\n",
        "\n",
        "Hence, the appropriate solution is to use the BinaryCrossEntropy loss.\n",
        "\n",
        "**Consequently, models should have sigmoid as the last activation function to handle multi-label classification tasks correctly.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TSQPYZ9P6j2",
        "outputId": "51a0d057-dfef-44a5-a162-30ab5b63085d"
      },
      "outputs": [],
      "source": [
        "## ----- Global Variables ----- ##\n",
        "batch_size      = 100\n",
        "learning_rate   = 0.001\n",
        "epochs          = 10\n",
        "evaluate_period = 2\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Device: {device}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XIv3DI7bauHu"
      },
      "source": [
        "### Auxiliar functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1P1wRKXcjhF"
      },
      "outputs": [],
      "source": [
        "def get_partial_dataset(path, save_filename='partial_dataset', n_samples=30000):\n",
        "  '''\n",
        "    Creates a partial dataset for training\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : str\n",
        "      Path to the _classes.csv file.\n",
        "\n",
        "    save_filename : str\n",
        "      Name of the file to be saved.\n",
        "\n",
        "    n_samples : int\n",
        "      Specifies the number of samples for training.\n",
        "  '''\n",
        "\n",
        "  df = pd.read_csv(path)\n",
        "  idxs = []\n",
        "\n",
        "  # --- Remove samples without class labels --- #\n",
        "  for i, row in df.iterrows():\n",
        "      if row[1:].sum() == 0:\n",
        "          idxs.append(i)\n",
        "\n",
        "  df.drop(idxs, inplace=True)\n",
        "\n",
        "  # --- Randomly remove samples --- #\n",
        "  idxs = df.sample(df.shape[0] - n_samples).index\n",
        "  df   = df.drop(idxs).reset_index(drop=True)\n",
        "\n",
        "  # --- Save locally --- #\n",
        "  # Include the Google Drive path to ensure the preservation of this information!\n",
        "  df.to_csv(f'{save_filename}.csv', index=False)\n",
        "\n",
        "# get_partial_dataset('COCO-multiclass/train/full_dataset.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Te-NlQ7MazU0"
      },
      "source": [
        "### Class Dataset and DataLoader\n",
        "\n",
        "*Obs: Learn more in [Dataset and Dataloader Tutorial Pytorch](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErpQQVoY5Uc0"
      },
      "outputs": [],
      "source": [
        "class COCOMulticlass(Dataset):\n",
        "  '''\n",
        "    Dataset class\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    __init__():\n",
        "      annotations_file : str\n",
        "        Path to the _classes.csv file or partial_dataset.csv file\n",
        "\n",
        "      img_dir : str\n",
        "        Path to the directory containing the images\n",
        "\n",
        "      transform : torchvision.transforms\n",
        "        Image transformations from the torchvision library.\n",
        "  '''\n",
        "\n",
        "  def __init__(self, annotations_file, img_dir, transform=None):\n",
        "      self.img_labels = pd.read_csv(annotations_file)\n",
        "      self.img_dir    = img_dir\n",
        "      self.transform  = transform\n",
        "      self.classes_names = self.img_labels.columns[1:]\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "      image    = Image.open(img_path)\n",
        "      label    = torch.Tensor(self.img_labels.iloc[idx, 1:].values.astype(float))\n",
        "\n",
        "      if self.transform:\n",
        "          image = self.transform(image)\n",
        "\n",
        "      return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKzOvKW45a2i"
      },
      "outputs": [],
      "source": [
        "# --- Image transformations --- #\n",
        "data_transform = Compose([Resize((224,224)), ToTensor()])\n",
        "\n",
        "# --- Datasets --- #\n",
        "train_dataset = COCOMulticlass('COCO-multiclass/train/partial_dataset.csv', 'COCO-multiclass/train', transform=data_transform)\n",
        "valid_dataset = COCOMulticlass('COCO-multiclass/valid/_classes.csv', 'COCO-multiclass/valid', transform=data_transform)\n",
        "\n",
        "# --- DataLoaders --- #\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# --- Classes --- #\n",
        "class_names = train_dataset.classes_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "gESWzqMdP3pn",
        "outputId": "7cc20332-070a-45c6-ab2e-79b606c86844"
      },
      "outputs": [],
      "source": [
        "## ------ Plot Data ----- ##\n",
        "fig, axes = plt.subplots(4, 10, figsize=(30,15), subplot_kw={'xticks':[], 'yticks':[]})\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    data, target = train_dataset.__getitem__(i*10)\n",
        "    ax.imshow(data.permute(1,2,0), cmap='binary', interpolation='nearest')\n",
        "    ax.set_title(''.join(class_names[target == 1]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qKZarHnKbUzk"
      },
      "source": [
        "### Train and Evaluate functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qahIqBpVP9RO"
      },
      "outputs": [],
      "source": [
        "def Criterion(preds, targets):\n",
        "    bce = nn.BCELoss().to(device)\n",
        "    loss = bce(preds + 1e-10, targets)\n",
        "    pred_labels = (preds > 0.5).float()\n",
        "    acc = accuracy_score(targets.cpu(), pred_labels.cpu())\n",
        "    f1 = f1_score(targets.cpu(), pred_labels.cpu(), average='samples')\n",
        "    precision = precision_score(targets.cpu(), pred_labels.cpu(), average='samples')\n",
        "    recall = recall_score(targets.cpu(), pred_labels.cpu(), average='samples')\n",
        "    return loss, acc, f1, precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlsKaGZzP8UO"
      },
      "outputs": [],
      "source": [
        "def train_batch(model, data, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    ims, targets = data\n",
        "    ims     = ims.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "    preds   = model(ims)\n",
        "    loss, acc, f1, pre, rec = criterion(preds, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    return loss.item(), acc.item(), f1.item(), pre.item(), rec.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def validate_batch(model, data, criterion, device):\n",
        "    model.eval()\n",
        "    ims, targets = data\n",
        "    ims     = ims.to(device=device)\n",
        "    targets = targets.to(device=device)\n",
        "    preds   = model(ims)\n",
        "    loss, acc, f1, pre, rec = criterion(preds, targets)\n",
        "    return loss.item(), acc.item(), f1.item(), pre.item(), rec.item()\n",
        "\n",
        "def save_model(model, best_loss, current_loss, sufix):\n",
        "  '''\n",
        "    Save the best model weights.\n",
        "    This function saves the weights locally.\n",
        "    To prevent data loss, consider adding the Google Drive path in the `torch.save()` function.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    model : nn.Module\n",
        "      Model to save the weights.\n",
        "\n",
        "    best_loss : float\n",
        "      Best loss achieved so far.\n",
        "\n",
        "    current_loss : float\n",
        "      Current loss to compare with the best loss.\n",
        "  '''\n",
        "  if best_loss == None:\n",
        "    best_loss = current_loss\n",
        "    torch.save(model.state_dict(), 'weights'+ sufix +'.pth')\n",
        "\n",
        "  elif best_loss > current_loss:\n",
        "    best_loss = current_loss\n",
        "    torch.save(model.state_dict(), 'weights'+ sufix +'.pth')\n",
        "\n",
        "  else: pass\n",
        "  return best_loss\n",
        "\n",
        "def load_model(path, model):\n",
        "  '''\n",
        "    Load the model weights.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    path : str\n",
        "      Path to the .pth file containing the weights.\n",
        "\n",
        "    model : nn.Module\n",
        "      Model to load the weights into.\n",
        "  '''\n",
        "  model.load_state_dict(torch.load(path))\n",
        "  return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nbac1PpKP5Xq"
      },
      "source": [
        "### 1. (3 points) Buil and train a Convolutional Neural Network (CNN) for Multi-Label Image Classification.\n",
        "\n",
        "*Tip 1: Apply a weight regularization to avoid overfitting and improve the performance of the CNN (for example, l1, l2, l1 and l2).*\n",
        "\n",
        "*Tip 2: Remember to use regularization layers, such as Dropout, BatchNorm and LayerNorm.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFPJIXKrQIm3"
      },
      "outputs": [],
      "source": [
        "def conv_block(nchannels_in, nchannels_out, stride_val, conv_kernel_size=3, pool_kernel_size=2):\n",
        "    return nn.Sequential(\n",
        "        # defining convolutional layer\n",
        "        nn.Conv2d(\n",
        "            in_channels=nchannels_in,\n",
        "            out_channels=nchannels_out,\n",
        "            kernel_size=conv_kernel_size,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            bias=True,\n",
        "        ),\n",
        "        # defining activation layer\n",
        "        nn.ReLU(),\n",
        "        # defining a pooling layer\n",
        "        nn.MaxPool2d(kernel_size=pool_kernel_size,\n",
        "                     stride=stride_val, padding=1),\n",
        "    )\n",
        "\n",
        "\n",
        "class HandcraftCNN_v1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HandcraftCNN_v1, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            conv_block(3, 16, 2),\n",
        "            conv_block(16, 64, 2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=207936, out_features=64, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.20),\n",
        "            nn.Linear(64, 128, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.20),\n",
        "            nn.Linear(128, len(class_names)),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        # transforms outputs into a 2D tensor\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        # classifies features\n",
        "        y = self.classifier(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "class HandcraftCNN_v2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HandcraftCNN_v2, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            conv_block(3, 16, 1),\n",
        "            conv_block(16, 32, 2),\n",
        "            conv_block(32, 64, 3)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=92416, out_features=128, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.20),\n",
        "            nn.Linear(128, 256, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.20),\n",
        "            nn.Linear(256, 512, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.20),\n",
        "            nn.Linear(512, len(class_names)),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        # transforms outputs into a 2D tensor\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        # classifies features\n",
        "        y = self.classifier(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "model_v1 = HandcraftCNN_v1()\n",
        "model_v2 = HandcraftCNN_v2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEcUxsdZQQs1"
      },
      "outputs": [],
      "source": [
        "\n",
        "optimizer = torch.optim.Adam(model_v1.parameters(), lr=learning_rate)\n",
        "criterion = Criterion\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
        "log = Report(epochs)\n",
        "\n",
        "model_v1.to(device)\n",
        "\n",
        "best_loss = None\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    # --- Train Model --- #\n",
        "    N = len(train_loader)\n",
        "    for bx, data in enumerate(train_loader):\n",
        "        loss, acc, f1, pre, rec = train_batch(\n",
        "            model_v1, data, optimizer, criterion, device)\n",
        "        # report results for the batch\n",
        "        log.record((epoch+(bx+1)/N), trn_loss=loss, trn_acc=acc,\n",
        "                   trn_f1=f1, trn_pre=pre, trn_rec=rec, end='\\r')\n",
        "\n",
        "    loss = 0\n",
        "    N = len(valid_loader)\n",
        "    for bx, data in enumerate(valid_loader):\n",
        "        loss, acc, f1, pre, rec = validate_batch(\n",
        "            model_v1, data, criterion, device)\n",
        "        log.record((epoch+(bx+1)/N), val_loss=loss, val_acc=acc,\n",
        "                   val_f1=f1, val_pre=pre, val_rec=rec, end='\\r')\n",
        "        \n",
        "\n",
        "    # --- Evaluate model in N epochs --- #\n",
        "    if (epoch + 1) % evaluate_period == 0:\n",
        "        log.report_avgs(epoch+1)\n",
        "        # --- Save best model weights --- #\n",
        "        best_loss = save_model(model_v1, best_loss, loss, '_v1')\n",
        "\n",
        "    lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-niA1CR8QS0r"
      },
      "outputs": [],
      "source": [
        "log.plot_epochs(['trn_loss','val_loss'])\n",
        "log.plot_epochs(['trn_acc','val_acc'])\n",
        "log.plot_epochs(['trn_f1','val_f1'])\n",
        "log.plot_epochs(['trn_pre','val_pre'])\n",
        "log.plot_epochs(['trn_rec','val_rec'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6kP4CzPEbcDT"
      },
      "source": [
        "### Visualize model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfi2iMSaQXNa"
      },
      "outputs": [],
      "source": [
        "def show_prediction(model, dataloader, class_names):\n",
        "  '''\n",
        "  Show a sample prediction.\n",
        "\n",
        "  Parameters:\n",
        "  -----------\n",
        "  model : nn.Module\n",
        "    Model to be evaluated.\n",
        "\n",
        "  dataloader : dataloader\n",
        "    DataLoader for the example.\n",
        "\n",
        "  class_names : list\n",
        "    List containing the class names.\n",
        "\n",
        "  '''\n",
        "  data, target = next(iter(dataloader))\n",
        "  data = data.to(device)\n",
        "  logits = model(data.type(torch.float))\n",
        "  np.set_printoptions(precision=5, suppress=True)\n",
        "  print(logits.detach().cpu().numpy()[0])\n",
        "  pred   = np.array(logits.cpu() > .5, dtype=float)\n",
        "  plt.imshow(data[0].cpu().permute(1,2,0))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  target = ''.join(class_names[target[0] == 1])\n",
        "  pred   = ''.join(class_names[pred[0] == 1])\n",
        "  print(f\"Target: {target}\\nPred: {pred if len(pred) != 0 else 'NONE'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xX9qxW1QYYN"
      },
      "outputs": [],
      "source": [
        "model_v1.eval()\n",
        "show_prediction(model_v1, valid_loader, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "optimizer = torch.optim.Adam(model_v2.parameters(), lr=learning_rate)\n",
        "criterion = Criterion\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)\n",
        "log = Report(epochs)\n",
        "\n",
        "model_v2.to(device)\n",
        "\n",
        "best_loss = None\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    # --- Train Model --- #\n",
        "    N = len(train_loader)\n",
        "    for bx, data in enumerate(train_loader):\n",
        "        loss, acc, f1, pre, rec = train_batch(\n",
        "            model_v2, data, optimizer, criterion, device)\n",
        "        # report results for the batch\n",
        "        log.record((epoch+(bx+1)/N), trn_loss=loss, trn_acc=acc,\n",
        "                   trn_f1=f1, trn_pre=pre, trn_rec=rec, end='\\r')\n",
        "\n",
        "    b_loss = []\n",
        "    N = len(valid_loader)\n",
        "    for bx, data in enumerate(valid_loader):\n",
        "        loss, acc, f1, pre, rec = validate_batch(\n",
        "            model_v1, data, criterion, device)\n",
        "        log.record((epoch+(bx+1)/N), val_loss=loss, val_acc=acc,\n",
        "                   val_f1=f1, val_pre=pre, val_rec=rec, end='\\r')\n",
        "        \n",
        "\n",
        "    # --- Evaluate model in N epochs --- #\n",
        "    if (epoch + 1) % evaluate_period == 0:\n",
        "        log.report_avgs(epoch+1)\n",
        "        # --- Save best model weights --- #\n",
        "        best_loss = save_model(model_v2, best_loss, loss, '_v2')\n",
        "\n",
        "    lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log.plot_epochs(['trn_loss','val_loss'])\n",
        "log.plot_epochs(['trn_acc','val_acc'])\n",
        "log.plot_epochs(['trn_f1','val_f1'])\n",
        "log.plot_epochs(['trn_pre','val_pre'])\n",
        "log.plot_epochs(['trn_rec','val_rec'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_v2.eval()\n",
        "show_prediction(model_v2, valid_loader, class_names)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2R8KIVMZvyRZ"
      },
      "source": [
        " > What are the conclusions? Was this model sufficient for the task? Do the hyperparameters, such as learning rate, batch size, and others, impact the final result? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vkXToOmlQZPY"
      },
      "source": [
        "### 2. (3 points) Apply the Transfer Learning Technique by utilizing one of the pre-trained CNN models available in PyTorch as backbone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLmT1qF6Qacy"
      },
      "outputs": [],
      "source": [
        "def TransferLearningModel(nclasses):\n",
        "    # get the vgg16 model pretrained on ImageNet\n",
        "    model = models.vgg16(weights=\"IMAGENET1K_V1\")\n",
        "    # Specify you do not want to train the parameters of the model\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    # The vgg16 model consists of three modules: features, avgpool, and classifier.\n",
        "    # Change avgpool to return a feature map of size 1x1 instead of 7x7. This will create\n",
        "    # batches with 512x1x1 tensors.\n",
        "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "    # Change the classifier to one suitable for your dataset\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(128, nclasses),\n",
        "        nn.Sigmoid(),\n",
        "    )  \n",
        "    criterion = Criterion\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # Return the complete model information for training and evaluation\n",
        "    return (model.to(device), criterion, optimizer)\n",
        "\n",
        "\n",
        "model_tf, criterion, optimizer = TransferLearningModel(len(class_names))\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC_xwlAmQcPM"
      },
      "outputs": [],
      "source": [
        "model_tf.to(device)\n",
        "\n",
        "best_loss = None\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    # --- Train Model --- #\n",
        "    N = len(train_loader)\n",
        "    for bx, data in enumerate(train_loader):\n",
        "        loss, acc, f1, pre, rec = train_batch(\n",
        "            model_tf, data, optimizer, criterion, device)\n",
        "        # report results for the batch\n",
        "        log.record((epoch+(bx+1)/N), trn_loss=loss, trn_acc=acc,\n",
        "                   trn_f1=f1, trn_pre=pre, trn_rec=rec, end='\\r')\n",
        "\n",
        "    b_loss = []\n",
        "    N = len(valid_loader)\n",
        "    for bx, data in enumerate(valid_loader):\n",
        "        loss, acc, f1, pre, rec = validate_batch(\n",
        "            model_tf, data, criterion, device)\n",
        "        log.record((epoch+(bx+1)/N), val_loss=loss, val_acc=acc,\n",
        "                   val_f1=f1, val_pre=pre, val_rec=rec, end='\\r')\n",
        "        \n",
        "\n",
        "    # --- Evaluate model in N epochs --- #\n",
        "    if (epoch + 1) % evaluate_period == 0:\n",
        "        log.report_avgs(epoch+1)\n",
        "        # --- Save best model weights --- #\n",
        "        best_loss = save_model(model_tf, best_loss, loss, '_tf')\n",
        "\n",
        "    lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5J6834wQd5L"
      },
      "outputs": [],
      "source": [
        "log.plot_epochs(['trn_loss','val_loss'])\n",
        "log.plot_epochs(['trn_acc','val_acc'])\n",
        "log.plot_epochs(['trn_f1','val_f1'])\n",
        "log.plot_epochs(['trn_pre','val_pre'])\n",
        "log.plot_epochs(['trn_rec','val_rec'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AfukMt2Rbgue"
      },
      "source": [
        "### Visualize model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK21xVx_n5U3"
      },
      "outputs": [],
      "source": [
        "model_tf.eval()\n",
        "show_prediction(model_tf, valid_loader, class_names)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CiXx9Yi-wHsQ"
      },
      "source": [
        " > What are the conclusions? Does the performance improve? Is it better to freeze the entire model or update all the weights in this case? (1-2 paragraphs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0HLHQzWLQgQl"
      },
      "source": [
        "### 3. (3 points) Apply the Data Augmentation technique to either the handcrafted model or the transfer learning model.\n",
        "\n",
        "*Tip: Be careful to choose appropriate transformations that do not destroy the information of the sample.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1PfNlmlQel-"
      },
      "outputs": [],
      "source": [
        "## TODO: Implement data augmentation during training. Choose appropriate transformations.\n",
        "# Link: https://pytorch.org/vision/stable/transforms.html\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((300,300), interpolation=transforms.InterpolationMode.BILINEAR, \n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05,0.10), scale=(0.9,1.1), shear=(-2,2),\n",
        "                            interpolation=transforms.InterpolationMode.BILINEAR, \n",
        "                            fill=0),\n",
        "    transforms.CenterCrop(250),\n",
        "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR, \n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize((300,300), interpolation=transforms.InterpolationMode.BILINEAR, \n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.05,0.10), scale=(0.9,1.1), shear=(-2,2),\n",
        "                            interpolation=transforms.InterpolationMode.BILINEAR, \n",
        "                            fill=0),\n",
        "    transforms.CenterCrop(250),\n",
        "    transforms.Resize((224,224), interpolation=transforms.InterpolationMode.BILINEAR, \n",
        "                      max_size=None, antialias=True),\n",
        "    transforms.ToTensor()  \n",
        "])\n",
        "\n",
        "train_dataset = COCOMulticlass('TCOCO-multiclass/train/partial_dataset.csv', 'COCO-multiclass/train', transform=train_transforms)\n",
        "valid_dataset = COCOMulticlass('COCO-multiclass/valid/_classes.csv', 'COCO-multiclass/valid', transform=valid_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_tf_aug, criterion, optimizer = TransferLearningModel(len(class_names))\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDeJenInQlgV"
      },
      "outputs": [],
      "source": [
        "model_tf_aug.to(device)\n",
        "\n",
        "best_loss = None\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "    # --- Train Model --- #\n",
        "    N = len(train_loader)\n",
        "    for bx, data in enumerate(train_loader):\n",
        "        loss, acc, f1, pre, rec = train_batch(\n",
        "            model_tf_aug, data, optimizer, criterion, device)\n",
        "        # report results for the batch\n",
        "        log.record((epoch+(bx+1)/N), trn_loss=loss, trn_acc=acc,\n",
        "                   trn_f1=f1, trn_pre=pre, trn_rec=rec, end='\\r')\n",
        "\n",
        "    b_loss = []\n",
        "    N = len(valid_loader)\n",
        "    for bx, data in enumerate(valid_loader):\n",
        "        loss, acc, f1, pre, rec = validate_batch(\n",
        "            model_tf_aug, data, criterion, device)\n",
        "        log.record((epoch+(bx+1)/N), val_loss=loss, val_acc=acc,\n",
        "                   val_f1=f1, val_pre=pre, val_rec=rec, end='\\r')\n",
        "        \n",
        "\n",
        "    # --- Evaluate model in N epochs --- #\n",
        "    if (epoch + 1) % evaluate_period == 0:\n",
        "        log.report_avgs(epoch+1)\n",
        "        # --- Save best model weights --- #\n",
        "        best_loss = save_model(model_tf_aug, best_loss, loss, '_tf_aug')\n",
        "\n",
        "    lr_scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log.plot_epochs(['trn_loss','val_loss'])\n",
        "log.plot_epochs(['trn_acc','val_acc'])\n",
        "log.plot_epochs(['trn_f1','val_f1'])\n",
        "log.plot_epochs(['trn_pre','val_pre'])\n",
        "log.plot_epochs(['trn_rec','val_rec'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_tf_aug.eval()\n",
        "show_prediction(model_tf, valid_loader, class_names)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uGeODHurZRn9"
      },
      "source": [
        " > What are the conclusions? Does the performance improve? (1-2 paragraphs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "a4e1ZRx4cLMX",
        "XIv3DI7bauHu",
        "Te-NlQ7MazU0",
        "qKZarHnKbUzk",
        "nbac1PpKP5Xq",
        "6kP4CzPEbcDT",
        "vkXToOmlQZPY",
        "AfukMt2Rbgue",
        "0HLHQzWLQgQl",
        "xt5ox0fgbo6e",
        "ebCU1MTXbr3c",
        "CueTdvfXbv9R",
        "R2HTBhK3aAte",
        "UtyL9_3jb2TO"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
